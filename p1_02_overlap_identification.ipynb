{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (phase 1) 02 Class overlap quantification and identification\n",
    "\n",
    "The identification and quantification of class overlap is a key step of the study. In this notebook, overlapping regions/instances are detected using three different methods.\n",
    "\n",
    "\n",
    "- 1. (Structural Overlap), N1 metric\n",
    "- 2. (Instance Overlap), Clst. Number of clusters needed to cover the entire data domain, building the ratio between pure, containing instances of the same class, and mixed clusters, which present instances of the two opposite classes.\n",
    "- 3. Discriminant analysis (SVDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, data and visualize overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import squareform\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import gower\n",
    "import prince\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, recall_score, roc_auc_score, roc_curve, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import euclidean, hamming\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# import from custom package\n",
    "from auxFuns.EDA import *\n",
    "from auxFuns.modelling import *\n",
    "from auxFuns.class_overlap import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'auxFuns.class_overlap' from 'c:\\\\Users\\\\angel\\\\Documents\\\\VSCode\\\\rsv_modelling_transfer_learning\\\\auxFuns\\\\class_overlap.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import auxFuns.EDA \n",
    "importlib.reload(auxFuns.EDA)\n",
    "\n",
    "import auxFuns.modelling\n",
    "importlib.reload(auxFuns.modelling)\n",
    "\n",
    "import auxFuns.class_overlap\n",
    "importlib.reload(auxFuns.class_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load phase 1 data\n",
    "raw_datasets_path = os.getcwd() + '/datasets/raw'\n",
    "processed_datasets_path = os.getcwd() + '/datasets/processed'\n",
    "\n",
    "# Phase 1 data\n",
    "rsv_predictors_df_v2 = pd.read_csv(processed_datasets_path + '/rsv_predictors_phase1_daysDedup_seasons_prevTest_v2.csv',low_memory=False)\n",
    "rsv_predictors_phase1_df = make_it_categorical_v2(rsv_predictors_df_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86058, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Following the model selection step, these are the final features taken for modelling\n",
    "selected_features_v2 = ['n_tests_that_day', 'sine','cosine', 'previous_test_daydiff',\n",
    "                     'Bronchitis', 'CCI',\n",
    "                     'Acute_upper_respiratory_infection', 'n_immunodeficiencies', 'n_symptoms',\n",
    "                     'healthcare_seeking', \n",
    "                     'General_symptoms_and_signs', 'prev_positive_rsv', 'Influenza',\n",
    "                     'key_comorbidities','Pneumonia',\n",
    "                     'season','month_of_the_test','multiple_tests',\n",
    "                     'BPA','BPAI']\n",
    "selected_features_v2.append('RSV_test_result')\n",
    "\n",
    "df_modelling_phase1 = rsv_predictors_phase1_df[selected_features_v2]\n",
    "\n",
    "df_modelling_phase1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of class overlap\n",
    "# As the data is high dimensional, it is needed to bring it to a lower dimension for accessible visualization\n",
    "\n",
    "random_seed = 40\n",
    "n_components = 5\n",
    "\n",
    "X = df_modelling_phase1.drop(['RSV_test_result'], axis = 1)\n",
    "\n",
    "famd = prince.FAMD(n_components=n_components, random_state=random_seed)\n",
    "famd = famd.fit(X)\n",
    "\n",
    "df_visualization = famd.transform(X)\n",
    "\n",
    "# Ensure both df1 and df_transformed present the same records in the same order\n",
    "df_modelling_phase1 = df_modelling_phase1.sort_index()\n",
    "df_visualization = df_visualization.sort_index()\n",
    "\n",
    "assert all(df_modelling_phase1.index == df_visualization.index), \"The indices of df1 and df_transformed do not match.\"\n",
    "\n",
    "df_visualization['RSV_test_result'] = df_modelling_phase1['RSV_test_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_red = (0.9, 0.4, 0.4) # RGB for light red\n",
    "light_green = (0.4, 0.9, 0.4) # RGB for light green\n",
    "light_blue = (0.4, 0.4, 0.9) # RGB for light blue\n",
    "\n",
    "plot_5FMDA_planes(df = df_visualization, hue_target = 'RSV_test_result', palette = {'Positive':light_red, 'Negative':light_blue}, figsize = (10,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Structural overlap: N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the N1 and N1 augmented metric for 1-5 number of neighbours\n",
    "\n",
    "X_source = pd.get_dummies(X)\n",
    "labels = df_modelling_phase1.RSV_test_result\n",
    "same_class_neighbours_dict, N1_metric_dict, dist_matrix, ind = calculate_same_neighbours_and_N1(X = X_source, y = labels, n_neighbours = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented N1 > extension of N1 metric to class imbalance\n",
    "\n",
    "for n_neighbours in range(1,6):   \n",
    "    same_class_neighbours = same_class_neighbours_dict[n_neighbours]\n",
    "\n",
    "    print('\\n-------')\n",
    "    print(f'Augmented N1 metric for {n_neighbours} neighbours')\n",
    "    find_augmented_n1_metric_from_same_neighbours(same_class_neighbours = same_class_neighbours, labels = labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the presence of overlapping instances according to the N1 metric\n",
    "df_visualization_overlapping_regions = df_visualization.copy()\n",
    "df_visualization_overlapping_regions['overlapping']= ~same_class_neighbours_dict[1]\n",
    "\n",
    "bright_orange = (1.0, 0.8, 0.2) # RGB for light red\n",
    "light_light_blue = (0.4, 0.4, 0.6) # RGB for light blue\n",
    "\n",
    "plot_5FMDA_planes(df = df_visualization_overlapping_regions, hue_target = 'overlapping', palette = {True:bright_orange, False:light_light_blue}, figsize = (10,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instance-level overlap: Clusters\n",
    "\n",
    "Per eps_value, we want to obtain the following:\n",
    "- Number of clusters \n",
    "  number of noise points (and as a percentage of the total points)\n",
    "- number of positives in noise (and as a percentage)\n",
    "- number of clusters and of points in mixed/positive/negative clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_values = [0.05, 0.1, 0.5, 0.7, 0.9, 1, 1.1, 1.3, 1.5]\n",
    "min_samples_value = 5\n",
    "# we need to cluster using the famd data, if not it is not possible to build the clusters\n",
    "random_seed = 40\n",
    "n_components = 5\n",
    "X = df_modelling_phase1.drop(['RSV_test_result'], axis = 1)\n",
    "famd = prince.FAMD(n_components=n_components, random_state=random_seed)\n",
    "famd = famd.fit(X)\n",
    "X_famd = famd.transform(X)\n",
    "df_famd = pd.concat([X_famd, df_modelling_phase1['RSV_test_result']], axis = 1)\n",
    "results = []\n",
    "\n",
    "\n",
    "for eps_value in eps_values:\n",
    "    print('\\n----------')\n",
    "    print(f'Eps value of: {eps_value}')\n",
    "\n",
    "    # 0: fit dbscan and obtain labels\n",
    "    db = DBSCAN(eps = eps_value, min_samples = min_samples_value).fit(X_famd) \n",
    "    labels = db.labels_\n",
    "    df_famd['DBSCAN_labels'] = db.labels_\n",
    "\n",
    "    # 1. Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    p_noise = 100*(n_noise_/(X_famd.shape[0]))\n",
    "    print(f'Estimated number of clusters: {n_clusters_}')\n",
    "    print(f'Estimated number of noise points: {n_noise_} and percentage over total data domain: {p_noise}')\n",
    "\n",
    "    # 2. Number of positives in noise (and as a percentage)\n",
    "    df_famd['is_noise'] = df_famd['DBSCAN_labels'].apply(lambda x: 'Noise' if x == -1 else 'Clustered')\n",
    "    df_no_noise = df_famd.loc[df_famd['is_noise'] != 'Noise']\n",
    "\n",
    "    print('-----------')\n",
    "    total_pos = df_famd['RSV_test_result'].value_counts()[1]\n",
    "    print(f'Total number of positive records: {total_pos}')\n",
    "    for c in df_famd['is_noise'].unique():\n",
    "        cluster_df = df_famd.loc[df_famd['is_noise'] == c,:]\n",
    "        pos = cluster_df['RSV_test_result'].value_counts()['Positive']\n",
    "        print(f'Number of positives in {c}: {pos}')\n",
    "\n",
    "    # 3. Number of clusters and of points in mixed/positive/negative clusters\n",
    "\n",
    "    count_pos = 0\n",
    "    count_neg = 0\n",
    "    count_mix = 0\n",
    "    for cl in df_no_noise['DBSCAN_labels'].unique():\n",
    "        # print(f'Cluster {cl}')\n",
    "        cluster_df = df_famd.loc[df_famd['DBSCAN_labels'] == cl,:]\n",
    "        # neg = aux_df['RSV_test_result'].value_counts().iloc[0]\n",
    "        pos = cluster_df.RSV_test_result.value_counts()['Positive']\n",
    "        neg = cluster_df.RSV_test_result.value_counts()['Negative']\n",
    "\n",
    "        if neg == 0:\n",
    "            df_famd.loc[df_famd['DBSCAN_labels'] == cl, 'mixed_or_unique'] = 'Positive'\n",
    "            count_pos += 1\n",
    "        elif pos == 0:\n",
    "            df_famd.loc[df_famd['DBSCAN_labels'] == cl, 'mixed_or_unique'] = 'Negative'\n",
    "            count_neg += 1\n",
    "        else:\n",
    "            df_famd.loc[df_famd['DBSCAN_labels'] == cl, 'mixed_or_unique'] = 'Mixed'\n",
    "            count_mix += 1\n",
    "        \n",
    "        # if len(cluster_df['RSV_test_result'].value_counts()) > 1:\n",
    "        #     pos = cluster_df.RSV_test_result.value_counts()['Positive']\n",
    "        #     neg = cluster_df.RSV_test_result.value_counts()['Negative']\n",
    "        #     pos_to_neg = pos / neg\n",
    "        #     # print(f'Positive to negative ratio: {pos_to_neg}')\n",
    "        #     count_mix += 1\n",
    "        #     df_famd.loc[df_famd['DBSCAN_labels'] == cl, 'mixed_or_unique'] = 'Mixed'\n",
    "\n",
    "        # else: \n",
    "        #     dominant_label = aux_df['RSV_test_result'].value_counts().index[0]\n",
    "        #     if dominant_label == 1:\n",
    "        #         # print('Fully positive')\n",
    "        #         df_famd.loc[df_famd['DBSCAN_labels'] == cl, 'mixed_or_unique'] = 'Positive'\n",
    "        #         count_pos += 1\n",
    "        #     elif dominant_label == 0:\n",
    "        #         # print('Fully negative')\n",
    "        #         df_famd.loc[df_famd['DBSCAN_labels'] == cl, 'mixed_or_unique'] = 'Negative'\n",
    "        #         count_neg += 1\n",
    "    print('-------------')\n",
    "    print('Results of DBSCAN clustering:')\n",
    "    print(f'\\n# fully positive clusters: {count_pos}')\n",
    "    if count_pos != 0:\n",
    "        pos_obs = df_famd['mixed_or_unique'].value_counts()['Positive']\n",
    "    else: \n",
    "        pos_obs = 0\n",
    "    print(f'observacions on fully positive: {pos_obs}')\n",
    "\n",
    "    print(f'\\n# fully negative clusters: {count_neg}')\n",
    "    if count_neg != 0:\n",
    "        neg_obs = df_famd['mixed_or_unique'].value_counts()['Negative']\n",
    "    else: \n",
    "        neg_obs = 0\n",
    "    print(f'observacions on fully negative: {neg_obs}')\n",
    "\n",
    "    print(f'\\n# mixed clusters: {count_mix}')\n",
    "    if count_mix != 0:\n",
    "        mix_obs = df_famd['mixed_or_unique'].value_counts()['Mixed']\n",
    "    else: \n",
    "        mix_obs = 0\n",
    "    print(f'observacions on mixed clusters: {mix_obs}')\n",
    "\n",
    "    results.append({\n",
    "        'eps_value': eps_value,\n",
    "        'n_clusters_': n_clusters_,\n",
    "        'n_noise_': n_noise_,\n",
    "        'count_pos': count_pos,\n",
    "        'pos_obs': pos_obs,\n",
    "        'count_neg': count_neg,\n",
    "        'neg_obs': neg_obs,\n",
    "        'count_mix': count_mix,\n",
    "        'mix_obs': mix_obs\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Structural level: SVD\n",
    "\n",
    "- 1. Bring the data to a 3-D representation (and split in training and test)\n",
    "- 2. Train a SVD model in the training data to detect overlapping regions.\n",
    "- 3. Assign testing points to the overlapping or non-overlappintg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Bring data to a 3-D representation and split in training and test \n",
    "random_seed = 40\n",
    "n_components = 3\n",
    "\n",
    "X = df_modelling_phase1.drop(['RSV_test_result'], axis = 1)\n",
    "\n",
    "famd = prince.FAMD(n_components=n_components, random_state=random_seed)\n",
    "famd = famd.fit(X)\n",
    "X_3d = famd.transform(X)\n",
    "\n",
    "# train test split\n",
    "labels = df_modelling_phase1.RSV_test_result\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_3d, labels, test_size=0.2, random_state=random_seed, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting positive oneSVM...\n",
      "Fitting negative oneSVM...\n",
      "Finding distances to boundary ...\n",
      "Finding overlapping points...\n"
     ]
    }
   ],
   "source": [
    "# 2. Train a SVD to find the overlapping regions in the training datadf_\n",
    "X_training_positive = X_train.loc[labels == 'Positive',:]\n",
    "X_training_negative = X_train.loc[labels == 'Negative',:]\n",
    "\n",
    "# Train One-Class SVM for positive and negative samples, separately.\n",
    "print('Fitting positive oneSVM...')\n",
    "ocsvm_positive = OneClassSVM()\n",
    "ocsvm_positive.fit(X_training_positive)\n",
    "\n",
    "print('Fitting negative oneSVM...')\n",
    "ocsvm_negative = OneClassSVM()\n",
    "ocsvm_negative.fit(X_training_negative)\n",
    "\n",
    "# Distances for positive and negative datasets to their specific boundary\n",
    "print('Finding distances to boundary ...')\n",
    "distances_positive = ocsvm_positive.decision_function(X_training_positive)\n",
    "distances_negative = ocsvm_negative.decision_function(X_training_negative)\n",
    "\n",
    "# Find overlaps \n",
    "# Thereshold of 1 e-03 can be tuned\n",
    "print('Finding overlapping points...')\n",
    "threshold = 40\n",
    "overlapping_positive_mask = np.abs(distances_positive) < threshold\n",
    "overlapping_negative_mask = np.abs(distances_negative) < threshold\n",
    "all_overlapping_mask = np.concatenate([overlapping_positive_mask, overlapping_negative_mask], axis = 0)\n",
    "\n",
    "overlapping_positive_mask.sum(), overlapping_negative_mask.sum(), all_overlapping_mask.sum()\n",
    "\n",
    "# Reorder the X_train and y_train to ensure the overlapping has been correctly identified \n",
    "X_training = pd.concat([X_training_positive, X_training_negative], axis = 0)\n",
    "y_training = pd.concat([y_train[y_train == 'Positive'], y_train[y_train == 'Negative']], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788 1527\n"
     ]
    }
   ],
   "source": [
    "# Find overlaps in the training set\n",
    "# Thereshold of 1 e-03 can be tuned\n",
    "threshold = 20\n",
    "overlapping_positive_mask = np.abs(distances_positive) < threshold\n",
    "overlapping_negative_mask = np.abs(distances_negative) < threshold\n",
    "all_overlapping_mask = np.concatenate([overlapping_positive_mask, overlapping_negative_mask], axis = 0)\n",
    "print(overlapping_positive_mask.sum(), overlapping_negative_mask.sum())\n",
    "\n",
    "overlapping_positive_mask.sum(), overlapping_negative_mask.sum(), all_overlapping_mask.sum()\n",
    "\n",
    "# Reorder the X_train and y_train to ensure the overlapping has been correctly identified \n",
    "X_training = pd.concat([X_training_positive, X_training_negative], axis = 0)\n",
    "y_training = pd.concat([y_train[y_train == 'Positive'], y_train[y_train == 'Negative']], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_red = (0.9, 0.4, 0.4)\n",
    "light_blue = (0.4, 0.4, 0.9)\n",
    "\n",
    "def plot_contours_and_points(ax, axis1, axis2, Z_positive_norm, Z_negative_norm, X_training_positive, X_training_negative):\n",
    "    \"\"\"Plot contours and points on the given axes.\"\"\"\n",
    "    ax.contour(xx, yy, Z_positive_norm, levels=[-1, 0, 1], linewidths=2, colors='r')\n",
    "    ax.contour(xx, yy, Z_negative_norm, levels=[-1, 0, 1], linewidths=2, colors='b')\n",
    "    ax.scatter(X_training_positive[axis1], X_training_positive[axis2], c=light_red, s=1, label='Positive')\n",
    "    ax.scatter(X_training_negative[axis1], X_training_negative[axis2], c=light_blue, s=1, label='Negative')\n",
    "    \n",
    "    ax.set_title(f\"2D Projection ({axis1}, {axis2})\")\n",
    "    ax.set_xlabel(axis1)\n",
    "    ax.set_ylabel(axis2)\n",
    "    ax.legend()\n",
    "\n",
    "x_span = np.linspace(-20, 20, 50) \n",
    "y_span = np.linspace(-20, 20, 50)  \n",
    "xx, yy = np.meshgrid(x_span, y_span)\n",
    "grid_2d = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axis_combinations = [(0, 1), (0, 2), (1, 2)]\n",
    "\n",
    "for i, (axis1, axis2) in enumerate(axis_combinations):\n",
    "    constant_value = np.zeros(grid_2d.shape[0])\n",
    "    grid_3d = np.zeros((grid_2d.shape[0], 3))\n",
    "    grid_3d[:, axis1] = grid_2d[:, 0]\n",
    "    grid_3d[:, axis2] = grid_2d[:, 1]\n",
    "    grid_3d[:, 3 - axis1 - axis2] = constant_value  # third dimension filled with constants\n",
    "\n",
    "    Z_positive = ocsvm_positive.decision_function(grid_3d).reshape(xx.shape)\n",
    "    Z_negative = ocsvm_negative.decision_function(grid_3d).reshape(xx.shape)\n",
    "    \n",
    "    Z_positive_norm = (Z_positive - np.mean(Z_positive)) / np.std(Z_positive)\n",
    "    Z_negative_norm = (Z_negative - np.mean(Z_negative)) / np.std(Z_negative)\n",
    "    \n",
    "    plot_contours_and_points(axes[i], axis1, axis2, Z_positive_norm, Z_negative_norm, X_training_positive, X_training_negative)\n",
    "\n",
    "plt.suptitle(\"2D Projections of 3D One-Class SVM Boundaries\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Assign validation data points to overlapping or non overlapping\n",
    "# Find the distances of every validation point to the positive and negative boundaries\n",
    "distances_validation_positive = ocsvm_positive.decision_function(X_validation)\n",
    "distances_validation_negative = ocsvm_positive.decision_function(X_validation)\n",
    "\n",
    "overlapping_validation = []\n",
    "\n",
    "# Assign labels based on boundaries\n",
    "# threshold = 0.1  # Define a threshold for determining overlapping points\n",
    "for dist_pos, dist_neg in zip(distances_validation_positive, distances_validation_negative):\n",
    "    if np.abs(dist_pos) < threshold and np.abs(dist_neg) < threshold:\n",
    "        overlapping_validation.append('Overlapping')\n",
    "    elif np.abs(dist_pos) < threshold:\n",
    "        overlapping_validation.append('Likely Positive')\n",
    "    elif np.abs(dist_neg) < threshold:\n",
    "        overlapping_validation.append('Likely Negative')\n",
    "    else:\n",
    "        overlapping_validation.append('Non-overlapping')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------\n",
      "-------------------\n",
      "Fitting model on trainig data exclusively\n",
      "----------------\n",
      "Building non-overlapping model ...\n",
      "Training model ... RandomForestClassifier(random_state=42)\n",
      "Best training parameters:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 7}\n",
      "Best training f1-score:  0.01712885621846345\n",
      "----------------\n",
      "Building (yes) overlapping model ...\n",
      "Training model ... RandomForestClassifier(random_state=42)\n",
      "Best training parameters:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 14}\n",
      "Best training f1-score:  0.8852457149927364\n"
     ]
    }
   ],
   "source": [
    "# 4. Now, see if this helps in the prediction\n",
    "## 4.1. Fit the overlapping and non overlapping models in the two distinct regions\n",
    "print('\\n------------------')\n",
    "print('-------------------')\n",
    "print('Fitting model on trainig data exclusively')\n",
    "\n",
    "model_nonOverlapping, model_Overlapping = only_build_2overlapping_models(X = X_training, labels = y_training, is_overlapping = all_overlapping_mask, \n",
    "                                                                        random_seed = 42,\n",
    "                                                                        model_class_non_overlapping = RandomForestClassifier(),\n",
    "                                                                        param_grid_non_overlapping = {'n_estimators': [7, 14],'max_depth': [10, 20],'min_samples_split': [5, 10],'min_samples_leaf': [1, 4]},\n",
    "                                                                        cost_sensitive_non_overlapping = False, weight_dict_non_overlapping = {'Negative': 1, 'Positive': 15},\n",
    "                                                                        model_class_overlapping = RandomForestClassifier(),\n",
    "                                                                        param_grid_overlapping = {'n_estimators': [7, 14],'max_depth': [10, 20],'min_samples_split': [5, 10],'min_samples_leaf': [1, 4]},\n",
    "                                                                        cost_sensitive_overlapping = False, weight_dict_overlapping = {'Negative': 1, 'Positive': 15})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
