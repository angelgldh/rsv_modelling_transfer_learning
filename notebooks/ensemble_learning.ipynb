{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble learning\n",
    "Notebook to explore improvement in performance of building custom-made ensemble learners. The workflow is the following:\n",
    "1. Build-up of the individual learners and performance evaluation\n",
    "- LighGBM\n",
    "- XGBoost\n",
    "- Random forest\n",
    "- (Maybe) lasso regression\n",
    "In this part, we will also include the resampling of data performing upsampling + downsampling\n",
    "\n",
    "2. Study on how to ensemble them together for performance optimization\n",
    "- Hard voting (including predictive threshold performance optimization for all of them)\n",
    "- Soft voting (with a posterior predictive threshold optimization)\n",
    "- Stacking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from tqdm import tqdm\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from auxFuns.EDA import *\n",
    "from auxFuns.modelling import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'auxFuns.modelling' from 'c:\\\\Users\\\\angel\\\\Documents\\\\VSCode\\\\rsv_modelling_transfer_learning\\\\auxFuns\\\\modelling.py'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import auxFuns.modelling\n",
    "importlib.reload(auxFuns.modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets_path = os.getcwd() + '/datasets/raw'\n",
    "processed_datasets_path = os.getcwd() + '/datasets/processed'\n",
    "\n",
    "rsv_predictors_df_v2 = pd.read_csv(processed_datasets_path + '/rsv_predictors_phase1_daysDedup_seasons_prevTest.csv',low_memory=False)\n",
    "rsv_predictors_df_v2 = make_it_categorical_v2(rsv_predictors_df_v2)\n",
    "\n",
    "rsv_predictors_df_v2.shape\n",
    "\n",
    "# summary_function_rsv(rsv_predictors_df_v2)\n",
    "\n",
    "# Extract a reduced sample of the data for modelling\n",
    "# sample_size = 80000\n",
    "# sample_v2_df = rsv_predictors_df_v2.sample(n = sample_size, random_state=42)\n",
    "\n",
    "sample_v2_df = rsv_predictors_df_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['sex', 'marital_status', 'race','patient_regional_location', 'age_group',\n",
    "                     'Acute_upper_respiratory_infection','Influenza','Pneumonia','Bronchitis','Symptoms_and_signs__digestive_system_and_abdomen','General_symptoms_and_signs','any_symptom',\n",
    "                     'COPD','AIDS','Asthma_chronic','CCI',\n",
    "                     'sine','cosine','calendar_year', \n",
    "                     'healthcare_seeking', 'influenza_vaccine',\n",
    "                     'n_symptoms','prev_positive_rsv','previous_test_daydiff','n_immunodeficiencies', \n",
    "                     'tumor_indicator','tumor_last_year',\n",
    "                     'season',\n",
    "                     'n_tests_that_day']\n",
    "# selected_features = ['sex', 'marital_status', 'race', 'patient_regional_location', 'age_group',\n",
    "#                      'Acute_upper_respiratory_infection','Influenza','Pneumonia','Bronchitis','Symptoms_and_signs__digestive_system_and_abdomen','General_symptoms_and_signs','any_symptom',\n",
    "#                      'COPD','AIDS','Asthma_chronic','CCI',\n",
    "#                      'sine','cosine','calendar_year', \n",
    "#                      'healthcare_seeking', 'influenza_vaccine',\n",
    "#                      'n_symptoms','prev_positive_rsv','previous_test_daydiff','n_immunodeficiencies', \n",
    "#                      'tumor_indicator','tumor_last_year']\n",
    "selected_features.append('RSV_test_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling method chosen:\n",
      "\n",
      "Downsampling and Upweighting\n"
     ]
    }
   ],
   "source": [
    "df1 = sample_v2_df[selected_features]\n",
    "\n",
    "input_test_size = 0.2\n",
    "random_seed = 42\n",
    "\n",
    "X_train, y_train, X_test, y_test, sample_weights, preprocessor_rsv = preprocess_and_resample_rsv(\n",
    "    df1, input_test_size = input_test_size, random_seed = random_seed, resampling_technique = \"downsample_upweight\", ratio_maj_min = 0.7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Study resampling techniques (WIP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build-up of the models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. XGboost\n",
    "- Train it using the previous approach (GridSearchCV)\n",
    "- Train it using Bayesian parameter optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approach 1: GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1: GridSearch CV\n",
    "random_seed = 42\n",
    "cost_sensitive = True\n",
    "\n",
    "if cost_sensitive:\n",
    "    weight_dict = {\"Negative\": 1,\n",
    "                   \"Positive\": 50}\n",
    "    scale_pos_weight = weight_dict[\"Positive\"]/weight_dict[\"Negative\"]  # Use scale_pos_weight parameter\n",
    "    model_class = XGBClassifier(scale_pos_weight=scale_pos_weight,\n",
    "                                random_state=random_seed)\n",
    "else:\n",
    "    model_class = XGBClassifier(random_state=random_seed)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': range(20,205,15),\n",
    "    'max_depth': range(5,30,1),\n",
    "    'learning_rate': np.arange(0.01, 0.51, 0.05),\n",
    "    'min_child_weight': np.arange(1, 11, 1), \n",
    "    'gamma': np.arange(0.1, 0.5, 0.1) \n",
    "}\n",
    "\n",
    "target_scorer = make_scorer(f1_score, average='macro')\n",
    "n_cv_folds = 5\n",
    "\n",
    "# XGBoost needs labels in numeric format\n",
    "y_train_numeric = [1 if label == \"Positive\" else 0 for label in y_train]\n",
    "\n",
    "model1_xgb = train_model_rsv(model = model_class, param_grid = param_grid, target_scorer = target_scorer, n_cv_folds = n_cv_folds,\n",
    "                    X_train = X_train, y_train = y_train_numeric)\n",
    "\n",
    "optimal_threshold = find_optimal_moving_threshold(model = model1_xgb, X_test = X_test, y_test = y_test)\n",
    "__,__,__,__,__,__,f1, __ = calculate_performance_metrics_rsv(trained_model = model1_xgb, X_test = X_test, y_test = y_test,\n",
    "                                                         threshold = optimal_threshold, \n",
    "                                                         print_roc = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approach 2: Bayesian hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostClassifier_custom:\n",
    "\n",
    "    def __init__(self, scoring, max_evals, cost_sensitive_yn, sample_weights):\n",
    "        self.scoring = scoring\n",
    "        self.max_evals = max_evals\n",
    "        self.cost_sensitive = cost_sensitive_yn\n",
    "        self.sample_weights = sample_weights\n",
    "        self.best = None\n",
    "        self.model = None\n",
    "        self.score_f1 = None\n",
    "        self.score_auc = None\n",
    "        self.n_estimators_choice = list(range(20, 205, 25))\n",
    "\n",
    "        \n",
    "\n",
    "    def objective(self, space):\n",
    "        classifier = XGBClassifier(n_estimators = int(space['n_estimators']),\n",
    "                                    max_depth = int(space['max_depth']),\n",
    "                                    learning_rate = space['learning_rate'],\n",
    "                                    gamma = space['gamma'],\n",
    "                                    min_child_weight = space['min_child_weight'],\n",
    "                                    subsample = space['subsample'],\n",
    "                                    colsample_bytree = space['colsample_bytree'],\n",
    "                                    )\n",
    "        # classifier.fit(self.X_train, self.y_train, early_stopping_rounds = space['early_stopping_rounds'], eval_metric = 'logloss',  eval_set=eval_set, verbose=True)\n",
    "        if self.cost_sensitive:\n",
    "            classifier.fit(self.X_train, self.y_train, sample_weight = self.sample_weights)\n",
    "        else: \n",
    "            classifier.fit(self.X_train, self.y_train)\n",
    "\n",
    "        Scores = cross_val_score(estimator = classifier, X = self.X_train, y = self.y_train, cv = 10, scoring=self.scoring)\n",
    "        score = Scores.mean()\n",
    "        loss = 1-score\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print('--------------------------------------------------------------------')\n",
    "        print(f'Training XGBoost classifier with objective metric: {self.scoring}')\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        self.space = {\n",
    "        'max_depth' : hp.quniform('max_depth',  5, 21, 5),\n",
    "        'learning_rate' : hp.uniform('learning_rate', 0.010, 0.200),\n",
    "        'n_estimators' : hp.choice('n_estimators', self.n_estimators_choice),\n",
    "        'gamma' : hp.quniform('gamma', 0, 0.50, 0.1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 2),\n",
    "        'subsample' : hp.quniform('subsample', 0.6, 1, 0.1),\n",
    "        'colsample_bytree' : hp.quniform('colsample_bytree', 0.6, 1.0, 0.1),\n",
    "        'early_stopping_rounds': 100\n",
    "        }\n",
    "\n",
    "        trials = Trials()\n",
    "        print(\"Tuning Hyperparameters ...\")\n",
    "        self.best = fmin(fn=self.objective,\n",
    "                    space=self.space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=self.max_evals,\n",
    "                    trials=trials)\n",
    "        print(\"Best Hyperparameters: \", self.best)\n",
    "        self.fit_model()\n",
    "\n",
    "    def fit_model(self):\n",
    "        self.model = XGBClassifier(n_estimators = self.n_estimators_choice[self.best['n_estimators']],\n",
    "                                max_depth = int(self.best['max_depth']),\n",
    "                                learning_rate = self.best['learning_rate'],\n",
    "                                gamma = self.best['gamma'],\n",
    "                                min_child_weight = self.best['min_child_weight'],\n",
    "                                subsample = self.best['subsample'],\n",
    "                                colsample_bytree = self.best['colsample_bytree'], \n",
    "                                verbose = True\n",
    "                                )\n",
    "        # self.model.fit(self.X_train, self.y_train, early_stopping_rounds = self.space['early_stopping_rounds'], eval_metric = 'logloss')\n",
    "        if self.cost_sensitive:\n",
    "            self.model.fit(self.X_train, self.y_train, sample_weight = self.sample_weights)\n",
    "        else: \n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print('XGBoostClassifier Performance:')\n",
    "\n",
    "        # Scores_f1 = cross_val_score(estimator = self.model, X = self.X_train, y = self.y_train, cv = 10, scoring='f1')\n",
    "        # self.score_f1 = Scores_f1.mean()\n",
    "        # print(\"Train Set 10-Fold F1-Score: \", self.score)\n",
    "\n",
    "        # Scores_auc = cross_val_score(estimator = self.model, X = self.X_train, y = self.y_train, cv = 10, scoring='roc_auc')\n",
    "        # self.score_auc = Scores_auc.mean()\n",
    "        # print(\"Train Set 10-Fold F1-Score: \", self.score)\n",
    "\n",
    "    def predict(self, X_test, y_test):\n",
    "\n",
    "        optimal_threshold = find_optimal_moving_threshold(model = self.model, X_test = X_test, y_test = y_test)\n",
    "        self.score_auc,__,__,__,__,__,self.score_f1 = calculate_performance_metrics_rsv(trained_model = self.model, X_test = X_test, y_test = y_test,\n",
    "                                                         threshold = optimal_threshold, \n",
    "                                                         print_roc = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Training XGBoost classifier with objective metric: balanced_accuracy\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [02:24<00:00, 12.01s/trial, best loss: 0.28366882607512856]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.9, 'gamma': 0.30000000000000004, 'learning_rate': 0.1265924625201866, 'max_depth': 5.0, 'min_child_weight': 2.0, 'n_estimators': 4, 'subsample': 0.8}\n",
      "[12:14:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "XGBoostClassifier Performance:\n",
      "Optimal threshold: 0.6900000000000001\n",
      "Optimal f1: 0.35348837209302325\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [02:27<17:09, 147.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7824106296833311\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.21468926553672316\n",
      "Negative predictive value: 0.9756111825944555\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.35348837209302325\n",
      "--------------------------------------------------------------------\n",
      "Training XGBoost classifier with objective metric: f1\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [00:47<00:00,  3.98s/trial, best loss: 0.22202706374262815]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.8, 'gamma': 0.4, 'learning_rate': 0.02916068966412473, 'max_depth': 5.0, 'min_child_weight': 6.0, 'n_estimators': 7, 'subsample': 0.6000000000000001}\n",
      "[12:15:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "XGBoostClassifier Performance:\n",
      "Optimal threshold: 0.5700000000000001\n",
      "Optimal f1: 0.35348837209302325\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [03:19<09:09, 91.64s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7900250981895682\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.21468926553672316\n",
      "Negative predictive value: 0.9756111825944555\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.35348837209302325\n",
      "--------------------------------------------------------------------\n",
      "Training XGBoost classifier with objective metric: f1_micro\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [01:09<00:00,  5.80s/trial, best loss: 0.2687734687596184]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.8, 'gamma': 0.5, 'learning_rate': 0.07713572310730138, 'max_depth': 5.0, 'min_child_weight': 6.0, 'n_estimators': 4, 'subsample': 0.6000000000000001}\n",
      "[12:16:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "XGBoostClassifier Performance:\n",
      "Optimal threshold: 0.56\n",
      "Optimal f1: 0.3553826199740596\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [04:32<06:54, 82.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7826644227207538\n",
      "Precision / Positive predictive value: 0.5708333333333333\n",
      "Specificity: 0.9938253102331994\n",
      "Recall / sensitivity: 0.2580037664783427\n",
      "Negative predictive value: 0.9767852934244639\n",
      "Accuracy: 0.9711247966534976\n",
      "F-1: 0.3553826199740596\n",
      "--------------------------------------------------------------------\n",
      "Training XGBoost classifier with objective metric: f1_macro\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [01:07<00:00,  5.61s/trial, best loss: 0.28517776352626956]\n",
      "Best Hyperparameters:  {'colsample_bytree': 1.0, 'gamma': 0.0, 'learning_rate': 0.08936245821508768, 'max_depth': 5.0, 'min_child_weight': 6.0, 'n_estimators': 6, 'subsample': 0.9}\n",
      "[12:17:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "XGBoostClassifier Performance:\n",
      "Optimal threshold: 0.6900000000000001\n",
      "Optimal f1: 0.35348837209302325\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [05:42<05:11, 77.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7872069568193951\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.21468926553672316\n",
      "Negative predictive value: 0.9756111825944555\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.35348837209302325\n",
      "--------------------------------------------------------------------\n",
      "Training XGBoost classifier with objective metric: f1_weighted\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [01:44<00:00,  8.72s/trial, best loss: 0.27517739608677394]\n",
      "Best Hyperparameters:  {'colsample_bytree': 1.0, 'gamma': 0.0, 'learning_rate': 0.16700661295438024, 'max_depth': 5.0, 'min_child_weight': 8.0, 'n_estimators': 2, 'subsample': 0.9}\n",
      "[12:19:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "XGBoostClassifier Performance:\n",
      "Optimal threshold: 0.64\n",
      "Optimal f1: 0.35348837209302325\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [07:35<04:31, 90.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7760808755317885\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.21468926553672316\n",
      "Negative predictive value: 0.9756111825944555\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.35348837209302325\n",
      "--------------------------------------------------------------------\n",
      "Training XGBoost classifier with objective metric: precision\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [01:16<00:00,  6.40s/trial, best loss: 0.2515762676686215]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.9, 'gamma': 0.30000000000000004, 'learning_rate': 0.16113752094091888, 'max_depth': 5.0, 'min_child_weight': 2.0, 'n_estimators': 1, 'subsample': 0.8}\n",
      "[12:20:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "XGBoostClassifier Performance:\n",
      "Optimal threshold: 0.5700000000000001\n",
      "Optimal f1: 0.34688346883468835\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [08:55<02:54, 87.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7684212481220952\n",
      "Precision / Positive predictive value: 0.6183574879227053\n",
      "Specificity: 0.9952640728973083\n",
      "Recall / sensitivity: 0.24105461393596986\n",
      "Negative predictive value: 0.976301087915319\n",
      "Accuracy: 0.9719962816639554\n",
      "F-1: 0.34688346883468835\n",
      "--------------------------------------------------------------------\n",
      "Training XGBoost classifier with objective metric: recall\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [01:22<00:00,  6.88s/trial, best loss: 0.17476747276109494]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.6000000000000001, 'gamma': 0.0, 'learning_rate': 0.07950538207084898, 'max_depth': 10.0, 'min_child_weight': 4.0, 'n_estimators': 0, 'subsample': 0.7000000000000001}\n",
      "[12:22:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "XGBoostClassifier Performance:\n",
      "Optimal threshold: 0.0\n",
      "Optimal f1: 0.059854590542749254\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angel\\Documents\\VSCode\\rsv_modelling_transfer_learning\\auxFuns\\modelling.py:314: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  npv = tn / (tn + fn)\n",
      " 88%|████████▊ | 7/8 [10:21<01:26, 86.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5\n",
      "Precision / Positive predictive value: 0.030850569370206832\n",
      "Specificity: 0.0\n",
      "Recall / sensitivity: 1.0\n",
      "Negative predictive value: nan\n",
      "Accuracy: 0.030850569370206832\n",
      "F-1: 0.059854590542749254\n",
      "--------------------------------------------------------------------\n",
      "Training XGBoost classifier with objective metric: roc_auc\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [01:42<00:00,  8.52s/trial, best loss: 0.20218686602971636]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.6000000000000001, 'gamma': 0.5, 'learning_rate': 0.08694305887031364, 'max_depth': 10.0, 'min_child_weight': 10.0, 'n_estimators': 2, 'subsample': 0.9}\n",
      "[12:24:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "XGBoostClassifier Performance:\n",
      "Optimal threshold: 0.58\n",
      "Optimal f1: 0.2589073634204276\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [12:11<00:00, 91.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7365478118196882\n",
      "Precision / Positive predictive value: 0.3504823151125402\n",
      "Specificity: 0.9878904142437503\n",
      "Recall / sensitivity: 0.20527306967984935\n",
      "Negative predictive value: 0.9750310632506952\n",
      "Accuracy: 0.9637462235649547\n",
      "F-1: 0.2589073634204276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Approach 2: train the model using bayesian hyperparameter optimization\n",
    "\n",
    "# Scorings = ['accuracy', 'balanced_accuracy', 'f1', 'f1_micro', 'f1_macro', 'f1_weighted', 'precision', 'recall', 'roc_auc']\n",
    "scorings = ['balanced_accuracy', 'f1', 'f1_micro', 'f1_macro', 'f1_weighted', 'precision', 'recall', 'roc_auc']\n",
    "y_train_numeric = [1 if label == 'Positive' else 0 for label in y_train]\n",
    "\n",
    "best_models_xgb = {}\n",
    "\n",
    "for score in tqdm(scorings):\n",
    "    classifier = XGBoostClassifier_custom(scoring=score, max_evals=12, sample_weights = sample_weights, cost_sensitive_yn = True)\n",
    "    classifier.train(X_train, y_train_numeric)\n",
    "    classifier.predict(X_test, y_test)\n",
    "    best_models_xgb[score] = {'model': classifier.model, 'score_f1': classifier.score_f1, 'score_auc': classifier.score_auc}\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. LightGBM\n",
    "\n",
    "As the Bayesian hyperparameter has proven more effective, this approach will be followed here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGBMClassifier_custom:\n",
    "\n",
    "    def __init__(self, scoring, max_evals, cost_sensitive_yn, sample_weights):\n",
    "        self.scoring = scoring\n",
    "        self.max_evals = max_evals\n",
    "        self.cost_sensitive = cost_sensitive_yn\n",
    "        self.sample_weights = sample_weights\n",
    "        self.best = None\n",
    "        self.model = None\n",
    "        self.score_f1 = None\n",
    "        self.score_auc = None\n",
    "        self.n_estimators_choice = list(range(20, 205, 25))\n",
    "\n",
    "        \n",
    "    def objective(self, space):\n",
    "        classifier = lgbm.LGBMClassifier(n_estimators = space['n_estimators'],\n",
    "                                    max_depth = int(space['max_depth']),\n",
    "                                    learning_rate = space['learning_rate'],\n",
    "                                    min_child_weight = space['min_child_weight'],\n",
    "                                    subsample = space['subsample'],\n",
    "                                    colsample_bytree = space['colsample_bytree'],\n",
    "                                    )\n",
    "        \n",
    "        if self.cost_sensitive:\n",
    "            classifier.fit(self.X_train, self.y_train, sample_weight = self.sample_weights)\n",
    "        else: \n",
    "            classifier.fit(self.X_train, self.y_train)\n",
    "\n",
    "        Scores = cross_val_score(estimator = classifier, X = self.X_train, y = self.y_train, cv = 10, scoring=self.scoring)\n",
    "        score = Scores.mean()\n",
    "        loss = 1-score\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print('--------------------------------------------------------------------')\n",
    "        print(f'Training LightGBM classifier with objective metric: {self.scoring}')\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        self.space = {\n",
    "        'max_depth' : hp.quniform('max_depth', 5, 21, 5),\n",
    "        'learning_rate' : hp.uniform('learning_rate', 0.010, 0.200),\n",
    "        'n_estimators' : hp.choice('n_estimators', self.n_estimators_choice),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 2),\n",
    "        'subsample' : hp.quniform('subsample', 0.6, 1, 0.1),\n",
    "        'colsample_bytree' : hp.quniform('colsample_bytree', 0.6, 1.0, 0.1),\n",
    "        }\n",
    "\n",
    "        trials = Trials()\n",
    "        print(\"Tuning Hyperparameters ...\")\n",
    "        self.best = fmin(fn=self.objective,\n",
    "                    space=self.space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=self.max_evals,\n",
    "                    trials=trials)\n",
    "        print(\"Best Hyperparameters: \", self.best)\n",
    "        self.fit_model()\n",
    "\n",
    "    def fit_model(self):\n",
    "        self.model = lgbm.LGBMClassifier(n_estimators = self.n_estimators_choice[self.best['n_estimators']],\n",
    "                                max_depth = int(self.best['max_depth']),\n",
    "                                learning_rate = self.best['learning_rate'],\n",
    "                                min_child_weight = self.best['min_child_weight'],\n",
    "                                subsample = self.best['subsample'],\n",
    "                                colsample_bytree = self.best['colsample_bytree']\n",
    "                                )\n",
    "\n",
    "        if self.cost_sensitive:\n",
    "            self.model.fit(self.X_train, self.y_train, sample_weight = self.sample_weights)\n",
    "        else: \n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "        print('LightGBMClassifier Performance:')\n",
    "        # These should be part of the evaluation set, not the training set\n",
    "\n",
    "        # Scores_f1 = cross_val_score(estimator = self.model, X = self.X_train, y = self.y_train, cv = 10, scoring='f1')\n",
    "        # self.score_f1 = Scores_f1.mean()\n",
    "        # print(\"Train Set 10-Fold F1-Score: \", self.score_f1)\n",
    "\n",
    "        # Scores_auc = cross_val_score(estimator = self.model, X = self.X_train, y = self.y_train, cv = 10, scoring='roc_auc')\n",
    "        # self.score_auc = Scores_auc.mean()\n",
    "        # print(\"Train Set 10-Fold AUC Score: \", self.score_auc)\n",
    "\n",
    "    def predict(self, X_test, y_test):       \n",
    "        optimal_threshold = find_optimal_moving_threshold(model = self.model, X_test = X_test, y_test = y_test)\n",
    "        self.score_auc,__,__,__,__,__,self.score_f1 = calculate_performance_metrics_rsv(trained_model = self.model, X_test = X_test, y_test = y_test, threshold = optimal_threshold, print_roc = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Training LightGBM classifier with objective metric: balanced_accuracy\n",
      "Tuning Hyperparameters ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:38<00:00,  3.18s/trial, best loss: 0.28736599491354364]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.0887891203811311, 'max_depth': 15.0, 'min_child_weight': 8.0, 'n_estimators': 3, 'subsample': 0.9}\n",
      "LightGBMClassifier Performance:\n",
      "Optimal threshold: 0.91\n",
      "Optimal f1: 0.36997319034852544\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:42<04:55, 42.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8084914205421756\n",
      "Precision / Positive predictive value: 0.641860465116279\n",
      "Specificity: 0.9953839697859841\n",
      "Recall / sensitivity: 0.2598870056497175\n",
      "Negative predictive value: 0.9768782726363476\n",
      "Accuracy: 0.9726934696723216\n",
      "F-1: 0.36997319034852544\n",
      "--------------------------------------------------------------------\n",
      "Training LightGBM classifier with objective metric: f1\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [00:36<00:00,  3.06s/trial, best loss: 0.21499936157417743]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.03730759750586875, 'max_depth': 5.0, 'min_child_weight': 2.0, 'n_estimators': 5, 'subsample': 1.0}\n",
      "LightGBMClassifier Performance:\n",
      "Optimal threshold: 0.89\n",
      "Optimal f1: 0.36607142857142855\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:23<04:08, 41.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8140520621192329\n",
      "Precision / Positive predictive value: 0.8723404255319149\n",
      "Specificity: 0.9989209280019183\n",
      "Recall / sensitivity: 0.23163841807909605\n",
      "Negative predictive value: 0.976099818405483\n",
      "Accuracy: 0.9752498257029979\n",
      "F-1: 0.36607142857142855\n",
      "--------------------------------------------------------------------\n",
      "Training LightGBM classifier with objective metric: f1_micro\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [00:30<00:00,  2.53s/trial, best loss: 0.27098645737149885]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.038662975722522044, 'max_depth': 20.0, 'min_child_weight': 10.0, 'n_estimators': 3, 'subsample': 0.6000000000000001}\n",
      "LightGBMClassifier Performance:\n",
      "Optimal threshold: 0.86\n",
      "Optimal f1: 0.375\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [01:57<03:11, 38.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8090898324615972\n",
      "Precision / Positive predictive value: 0.7630057803468208\n",
      "Specificity: 0.9975421137821473\n",
      "Recall / sensitivity: 0.24858757062146894\n",
      "Negative predictive value: 0.9765831328129585\n",
      "Accuracy: 0.9744364396932372\n",
      "F-1: 0.375\n",
      "--------------------------------------------------------------------\n",
      "Training LightGBM classifier with objective metric: f1_macro\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [00:26<00:00,  2.17s/trial, best loss: 0.2844078223447395]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.8, 'learning_rate': 0.18183202094494266, 'max_depth': 5.0, 'min_child_weight': 8.0, 'n_estimators': 4, 'subsample': 0.9}\n",
      "LightGBMClassifier Performance:\n",
      "Optimal threshold: 0.9400000000000001\n",
      "Optimal f1: 0.3678756476683938\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [02:26<02:18, 34.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.804457883734113\n",
      "Precision / Positive predictive value: 0.5892116182572614\n",
      "Specificity: 0.9940651040105509\n",
      "Recall / sensitivity: 0.2674199623352166\n",
      "Negative predictive value: 0.9770785457545225\n",
      "Accuracy: 0.9716476876597723\n",
      "F-1: 0.3678756476683938\n",
      "--------------------------------------------------------------------\n",
      "Training LightGBM classifier with objective metric: f1_weighted\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [00:25<00:00,  2.16s/trial, best loss: 0.2706013887579325]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.05653146087281452, 'max_depth': 5.0, 'min_child_weight': 6.0, 'n_estimators': 6, 'subsample': 0.7000000000000001}\n",
      "LightGBMClassifier Performance:\n",
      "Optimal threshold: 0.93\n",
      "Optimal f1: 0.363103953147877\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [02:55<01:37, 32.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8150089792834659\n",
      "Precision / Positive predictive value: 0.8157894736842105\n",
      "Specificity: 0.9983214435585397\n",
      "Recall / sensitivity: 0.2335216572504708\n",
      "Negative predictive value: 0.9761430246189918\n",
      "Accuracy: 0.9747269346967232\n",
      "F-1: 0.363103953147877\n",
      "--------------------------------------------------------------------\n",
      "Training LightGBM classifier with objective metric: precision\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [00:24<00:00,  2.02s/trial, best loss: 0.24761021208655754]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.9, 'learning_rate': 0.05391254789268059, 'max_depth': 20.0, 'min_child_weight': 4.0, 'n_estimators': 3, 'subsample': 0.7000000000000001}\n",
      "LightGBMClassifier Performance:\n",
      "Optimal threshold: 0.9\n",
      "Optimal f1: 0.36619718309859156\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [03:23<01:01, 30.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8124124552320033\n",
      "Precision / Positive predictive value: 0.7262569832402235\n",
      "Specificity: 0.9970625262274444\n",
      "Recall / sensitivity: 0.2448210922787194\n",
      "Negative predictive value: 0.9764574649210357\n",
      "Accuracy: 0.9738554496862654\n",
      "F-1: 0.36619718309859156\n",
      "--------------------------------------------------------------------\n",
      "Training LightGBM classifier with objective metric: recall\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [00:21<00:00,  1.83s/trial, best loss: 0.14461422623793074]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.7000000000000001, 'learning_rate': 0.10620377200005032, 'max_depth': 5.0, 'min_child_weight': 4.0, 'n_estimators': 0, 'subsample': 1.0}\n",
      "LightGBMClassifier Performance:\n",
      "Optimal threshold: 0.76\n",
      "Optimal f1: 0.36535859269282817\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [03:47<00:28, 28.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.800020005394231\n",
      "Precision / Positive predictive value: 0.6490384615384616\n",
      "Specificity: 0.9956237635633355\n",
      "Recall / sensitivity: 0.2542372881355932\n",
      "Negative predictive value: 0.976711362032463\n",
      "Accuracy: 0.9727515686730188\n",
      "F-1: 0.36535859269282817\n",
      "--------------------------------------------------------------------\n",
      "Training LightGBM classifier with objective metric: roc_auc\n",
      "Tuning Hyperparameters ...\n",
      "100%|██████████| 12/12 [00:25<00:00,  2.12s/trial, best loss: 0.194394052027422]\n",
      "Best Hyperparameters:  {'colsample_bytree': 0.9, 'learning_rate': 0.03507671894512612, 'max_depth': 10.0, 'min_child_weight': 2.0, 'n_estimators': 5, 'subsample': 0.8}\n",
      "LightGBMClassifier Performance:\n",
      "Optimal threshold: 0.89\n",
      "Optimal f1: 0.37228260869565216\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:16<00:00, 32.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8076939143071422\n",
      "Precision / Positive predictive value: 0.6682926829268293\n",
      "Specificity: 0.9959235057850249\n",
      "Recall / sensitivity: 0.2580037664783427\n",
      "Negative predictive value: 0.9768330687364026\n",
      "Accuracy: 0.9731582616778991\n",
      "F-1: 0.37228260869565216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Scorings = ['accuracy', 'balanced_accuracy', 'f1', 'f1_micro', 'f1_macro', 'f1_weighted', 'precision', 'recall', 'roc_auc']\n",
    "scorings = ['balanced_accuracy', 'f1', 'f1_micro', 'f1_macro', 'f1_weighted', 'precision', 'recall', 'roc_auc']\n",
    "y_train_numeric = [1 if label == 'Positive' else 0 for label in y_train]\n",
    "\n",
    "best_models_lightGBM = {}\n",
    "\n",
    "for score in tqdm(scorings):\n",
    "    classifier = LightGBMClassifier_custom(scoring=score, max_evals=12, sample_weights = sample_weights, cost_sensitive_yn = True)\n",
    "    classifier.train(X_train, y_train_numeric)\n",
    "    classifier.predict(X_test, y_test)\n",
    "    best_models_lightGBM[score] = {'model': classifier.model, 'score_f1': classifier.score_f1, 'score_auc': classifier.score_auc}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ensemble of the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetaClassifier(trained_models, X_train, y_train, X_test, y_test, target_metric = 'f1', top_iterations = 5):\n",
    "    \"\"\"\n",
    "    Function to build a soft-voting ensemble meta-classifier\n",
    "    Arguments:\n",
    "    trained_models -- list of model iterations outputs of different algorithms\n",
    "    train_dict -- a dictionary of train set features and labels\n",
    "    test_dict (optional) -- a dictionary that contains test set features and labels\n",
    "    Return:\n",
    "    out -- a dictionary of meta-classifier model ('BestModel'), a dataframe of performance metrics of all models (Metrics), \n",
    "           and a dataframe of metaclassifier predicted labels and probabilities on trainset instances (train_df_pred)\n",
    "    \"\"\"\n",
    "\n",
    "    estimators=[]\n",
    "    weights = []\n",
    "    results_auc = []\n",
    "    results_f1 = []\n",
    "\n",
    "    train_dict = {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train \n",
    "    }\n",
    "    test_dict = {\n",
    "        'X_test ': X_test,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "\n",
    "    print('Generating a Soft-Voting Ensemble Classifier...')\n",
    "\n",
    "    for alg in tqdm(trained_models):\n",
    "        for metric in tqdm(list(alg.keys())):\n",
    "            # for voting ensemble\n",
    "            estimators.append((str(alg)+'_'+metric, alg[metric]['model']))\n",
    "            weights.append(alg[metric]['score_f1'])\n",
    "\n",
    "            # for results\n",
    "            optimal_threshold = find_optimal_moving_threshold(model = alg[metric]['model'], X_test = X_test, y_test = y_test)\n",
    "            score_auc,__,__,__,__,__,score_f1 = calculate_performance_metrics_rsv(trained_model = alg[metric]['model'], X_test = X_test, y_test = y_test, threshold = optimal_threshold, print_roc = False)\n",
    "            results_auc.append(score_auc)\n",
    "            results_f1.append(score_f1)\n",
    "\n",
    "    if target_metric == 'f1':\n",
    "        results_df = pd.DataFrame(results_f1, columns = ['f1'])\n",
    "    elif target_metric == 'auc':\n",
    "        results_df = pd.DataFrame(results_auc, columns = ['auc'])\n",
    "    else:\n",
    "        raise ValueError(\"Please, indicate a target metric. Accepted values are ['f1', 'auc']\")\n",
    "        \n",
    "   \n",
    "    results_df.sort_values(by= target_metric, ascending=False)\n",
    "\n",
    "    # keeping top five iterations for the ensemble\n",
    "    KeepIdx = results_df.nlargest(top_iterations, target_metric).index\n",
    "\n",
    "    BestEstimators= [estimators[i] for i in KeepIdx.tolist()]\n",
    "    BestWeights = [weights[i] for i in KeepIdx.tolist()]\n",
    "\n",
    "    X_train, y_train = train_dict['X_train'], train_dict['y_train']\n",
    "\n",
    "    MetaClassifier = VotingClassifier(estimators=BestEstimators, voting='soft', weights=BestWeights)\n",
    "    MetaClassifier = MetaClassifier.fit(X_train, y_train)\n",
    "\n",
    "    # results_df = results_df.append(eval_model(MetaClassifier, train_dict, test_dict), ignore_index=True).sort_values(by='train_CV_f1', ascending=False) # add metaclassification model metrics\n",
    "\n",
    "    optimal_threshold = find_optimal_moving_threshold(model = MetaClassifier, X_test = X_test, y_test = y_test)\n",
    "    __,__,__,__,__,__,__ = calculate_performance_metrics_rsv(trained_model = MetaClassifier, X_test = X_test, y_test = y_test, threshold = optimal_threshold, print_roc = False)\n",
    "            \n",
    "\n",
    "    # storing metaclassifier performance on trainset\n",
    "    # y_pred = MetaClassifier.predict(X_train)\n",
    "    # y_proba =  MetaClassifier.predict_proba(X_train)\n",
    "    # train_df_pred = X_train.copy()\n",
    "    # train_df_pred['y_true'] = y_train\n",
    "    # train_df_pred['y_hat'] = y_pred\n",
    "    # train_df_pred['y_hat_proba'] = y_proba[:,1] # probability of belonging to class 1\n",
    "\n",
    "    out = {'MetaClassifier': MetaClassifier,\n",
    "           'BestModel': BestEstimators}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a Soft-Voting Ensemble Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.6900000000000001\n",
      "Optimal f1: 0.35348837209302325\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7824106296833311\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.21468926553672316\n",
      "Negative predictive value: 0.9756111825944555\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.35348837209302325\n",
      "Optimal threshold: 0.5700000000000001\n",
      "Optimal f1: 0.35348837209302325\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7900250981895682\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.21468926553672316\n",
      "Negative predictive value: 0.9756111825944555\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.35348837209302325\n",
      "Optimal threshold: 0.56\n",
      "Optimal f1: 0.3553826199740596\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7826644227207538\n",
      "Precision / Positive predictive value: 0.5708333333333333\n",
      "Specificity: 0.9938253102331994\n",
      "Recall / sensitivity: 0.2580037664783427\n",
      "Negative predictive value: 0.9767852934244639\n",
      "Accuracy: 0.9711247966534976\n",
      "F-1: 0.3553826199740596\n",
      "Optimal threshold: 0.6900000000000001\n",
      "Optimal f1: 0.35348837209302325\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7872069568193951\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.21468926553672316\n",
      "Negative predictive value: 0.9756111825944555\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.35348837209302325\n",
      "Optimal threshold: 0.64\n",
      "Optimal f1: 0.35348837209302325\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7760808755317885\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.21468926553672316\n",
      "Negative predictive value: 0.9756111825944555\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.35348837209302325\n",
      "Optimal threshold: 0.5700000000000001\n",
      "Optimal f1: 0.34688346883468835\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7684212481220952\n",
      "Precision / Positive predictive value: 0.6183574879227053\n",
      "Specificity: 0.9952640728973083\n",
      "Recall / sensitivity: 0.24105461393596986\n",
      "Negative predictive value: 0.976301087915319\n",
      "Accuracy: 0.9719962816639554\n",
      "F-1: 0.34688346883468835\n",
      "Optimal threshold: 0.0\n",
      "Optimal f1: 0.059854590542749254\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\angel\\Documents\\VSCode\\rsv_modelling_transfer_learning\\auxFuns\\modelling.py:314: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  npv = tn / (tn + fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5\n",
      "Precision / Positive predictive value: 0.030850569370206832\n",
      "Specificity: 0.0\n",
      "Recall / sensitivity: 1.0\n",
      "Negative predictive value: nan\n",
      "Accuracy: 0.030850569370206832\n",
      "F-1: 0.059854590542749254\n",
      "Optimal threshold: 0.58\n",
      "Optimal f1: 0.2589073634204276\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:26<00:00,  3.31s/it]\n",
      " 50%|█████     | 1/2 [00:26<00:26, 26.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.7365478118196882\n",
      "Precision / Positive predictive value: 0.3504823151125402\n",
      "Specificity: 0.9878904142437503\n",
      "Recall / sensitivity: 0.20527306967984935\n",
      "Negative predictive value: 0.9750310632506952\n",
      "Accuracy: 0.9637462235649547\n",
      "F-1: 0.2589073634204276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.91\n",
      "Optimal f1: 0.36997319034852544\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8084914205421756\n",
      "Precision / Positive predictive value: 0.641860465116279\n",
      "Specificity: 0.9953839697859841\n",
      "Recall / sensitivity: 0.2598870056497175\n",
      "Negative predictive value: 0.9768782726363476\n",
      "Accuracy: 0.9726934696723216\n",
      "F-1: 0.36997319034852544\n",
      "Optimal threshold: 0.89\n",
      "Optimal f1: 0.36607142857142855\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8140520621192329\n",
      "Precision / Positive predictive value: 0.8723404255319149\n",
      "Specificity: 0.9989209280019183\n",
      "Recall / sensitivity: 0.23163841807909605\n",
      "Negative predictive value: 0.976099818405483\n",
      "Accuracy: 0.9752498257029979\n",
      "F-1: 0.36607142857142855\n",
      "Optimal threshold: 0.86\n",
      "Optimal f1: 0.375\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8090898324615972\n",
      "Precision / Positive predictive value: 0.7630057803468208\n",
      "Specificity: 0.9975421137821473\n",
      "Recall / sensitivity: 0.24858757062146894\n",
      "Negative predictive value: 0.9765831328129585\n",
      "Accuracy: 0.9744364396932372\n",
      "F-1: 0.375\n",
      "Optimal threshold: 0.9400000000000001\n",
      "Optimal f1: 0.3678756476683938\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.804457883734113\n",
      "Precision / Positive predictive value: 0.5892116182572614\n",
      "Specificity: 0.9940651040105509\n",
      "Recall / sensitivity: 0.2674199623352166\n",
      "Negative predictive value: 0.9770785457545225\n",
      "Accuracy: 0.9716476876597723\n",
      "F-1: 0.3678756476683938\n",
      "Optimal threshold: 0.93\n",
      "Optimal f1: 0.363103953147877\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8150089792834659\n",
      "Precision / Positive predictive value: 0.8157894736842105\n",
      "Specificity: 0.9983214435585397\n",
      "Recall / sensitivity: 0.2335216572504708\n",
      "Negative predictive value: 0.9761430246189918\n",
      "Accuracy: 0.9747269346967232\n",
      "F-1: 0.363103953147877\n",
      "Optimal threshold: 0.9\n",
      "Optimal f1: 0.36619718309859156\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8124124552320033\n",
      "Precision / Positive predictive value: 0.7262569832402235\n",
      "Specificity: 0.9970625262274444\n",
      "Recall / sensitivity: 0.2448210922787194\n",
      "Negative predictive value: 0.9764574649210357\n",
      "Accuracy: 0.9738554496862654\n",
      "F-1: 0.36619718309859156\n",
      "Optimal threshold: 0.76\n",
      "Optimal f1: 0.36535859269282817\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.800020005394231\n",
      "Precision / Positive predictive value: 0.6490384615384616\n",
      "Specificity: 0.9956237635633355\n",
      "Recall / sensitivity: 0.2542372881355932\n",
      "Negative predictive value: 0.976711362032463\n",
      "Accuracy: 0.9727515686730188\n",
      "F-1: 0.36535859269282817\n",
      "Optimal threshold: 0.89\n",
      "Optimal f1: 0.37228260869565216\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:23<00:00,  2.90s/it]\n",
      "100%|██████████| 2/2 [00:49<00:00, 24.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8076939143071422\n",
      "Precision / Positive predictive value: 0.6682926829268293\n",
      "Specificity: 0.9959235057850249\n",
      "Recall / sensitivity: 0.2580037664783427\n",
      "Negative predictive value: 0.9768330687364026\n",
      "Accuracy: 0.9731582616778991\n",
      "F-1: 0.37228260869565216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold: 0.92\n",
      "Optimal f1: 0.36549707602339176\n",
      "\n",
      "\n",
      "AUC Score: 0.8123084204081665\n",
      "Precision / Positive predictive value: 0.8169934640522876\n",
      "Specificity: 0.9983214435585397\n",
      "Recall / sensitivity: 0.23540489642184556\n",
      "Negative predictive value: 0.9762002462043496\n",
      "Accuracy: 0.9747850336974204\n",
      "F-1: 0.36549707602339176\n"
     ]
    }
   ],
   "source": [
    "metaclassifier_dict = MetaClassifier(trained_models = [best_models_xgb, best_models_lightGBM], \n",
    "                                     X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, target_metric = 'f1', top_iterations = 5\n",
    "                                     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
