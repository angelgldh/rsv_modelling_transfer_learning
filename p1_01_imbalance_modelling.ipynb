{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (phase 1) 01 Class imbalance modelling\n",
    "\n",
    "The population of phase 1 presents a high level of overlap, thus in this notebook the textbook approaches for class overlap are implemented:\n",
    "- Resampling techniques (4 different resampling techniques)\n",
    "- Various model classes: logistic regression, random forest and XGBoost\n",
    "- Cost sensitive learning and moving threshold is applied in every case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and load the data for phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, recall_score, roc_auc_score, roc_curve, average_precision_score\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import importlib\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import from custom package\n",
    "from auxFuns.EDA import *\n",
    "from auxFuns.modelling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'auxFuns.EDA' from 'c:\\\\Users\\\\angel\\\\Documents\\\\VSCode\\\\rsv_modelling_transfer_learning\\\\auxFuns\\\\EDA.py'>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import auxFuns.modelling \n",
    "importlib.reload(auxFuns.modelling)\n",
    "\n",
    "import auxFuns.EDA \n",
    "importlib.reload(auxFuns.EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load phase 1 data\n",
    "raw_datasets_path = os.getcwd() + '/datasets/raw'\n",
    "processed_datasets_path = os.getcwd() + '/datasets/processed'\n",
    "\n",
    "# Phase 1 data\n",
    "rsv_predictors_df_v2 = pd.read_csv(processed_datasets_path + '/rsv_predictors_phase1_daysDedup_seasons_prevTest_v2.csv',low_memory=False)\n",
    "rsv_predictors_phase1_df = make_it_categorical_v2(rsv_predictors_df_v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86058, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Following the model selection step, these are the final features taken for modelling\n",
    "selected_features_v2 = ['n_tests_that_day', 'sine','cosine', 'previous_test_daydiff',\n",
    "                     'Bronchitis', 'CCI',\n",
    "                     'Acute_upper_respiratory_infection', 'n_immunodeficiencies', 'n_symptoms',\n",
    "                     'healthcare_seeking', \n",
    "                     'General_symptoms_and_signs', 'prev_positive_rsv', 'Influenza',\n",
    "                     'key_comorbidities','Pneumonia',\n",
    "                     'season','month_of_the_test','multiple_tests',\n",
    "                     'BPA','BPAI']\n",
    "selected_features_v2.append('RSV_test_result')\n",
    "\n",
    "df_modelling_phase1 = rsv_predictors_phase1_df[selected_features_v2]\n",
    "\n",
    "df_modelling_phase1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Resampling of the data\n",
    "\n",
    "Four different techniques: \n",
    "- Random Undersampling: This involves removing some of the majority class instances. While it can help balance the classes, it may also remove important information, thereby affecting the model's ability to generalize.\n",
    "- Random Oversampling: This technique involves duplicating some minority class instances. Although this can balance the classes, it may lead to overfitting as the same instances are repeated.\n",
    "- SMOTE-NC, i.e. SMOTE (Synthetic Minority Oversampling Technique) adapted for mixed data (continuous and categorical variables). It generates synthetic instances of the minority class. While it adds diversity and avoids overfitting to some extent, it can also introduce noise.\n",
    "- Undersampling and Upweighting: This approach combines undersampling with the assignment of greater importance to the minority class. By upweighting the remaining majority instances, the model learns the imbalance of the actual data. It attempts to find a balance but may still risk losing information from the majority class or introducing bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----\n",
      "Resampling using None\n",
      "Resampling method chosen:\n",
      "\n",
      "None\n",
      "y_TRAIN imbalance ratio: 31.428638718794158\n",
      "y_TEST imbalance ratio: 31.41431261770245\n",
      "\n",
      "----\n",
      "Resampling using over\n",
      "Resampling method chosen:\n",
      "\n",
      "Oversampling\n",
      "y_TRAIN imbalance ratio: 1.2500093671550077\n",
      "y_TEST imbalance ratio: 31.41431261770245\n",
      "\n",
      "----\n",
      "Resampling using under\n",
      "Resampling method chosen:\n",
      "\n",
      "Undersampling\n",
      "y_TRAIN imbalance ratio: 1.249646726330664\n",
      "y_TEST imbalance ratio: 31.41431261770245\n",
      "\n",
      "----\n",
      "Resampling using smotenc\n",
      "Resampling method chosen:\n",
      "\n",
      "SMOTE-sampling\n",
      "y_TRAIN imbalance ratio: 1.2500093671550077\n",
      "y_TEST imbalance ratio: 31.41431261770245\n",
      "\n",
      "----\n",
      "Resampling using downsample_upweight\n",
      "Resampling method chosen:\n",
      "\n",
      "Downsampling and Upweighting\n",
      "y_TRAIN imbalance ratio: 0.7998115873763542\n",
      "y_TEST imbalance ratio: 31.41431261770245\n"
     ]
    }
   ],
   "source": [
    "resampling_techniques = ['None', 'over', 'under', 'smotenc', 'downsample_upweight']\n",
    "input_test_size = 0.2\n",
    "random_seed = 42\n",
    "\n",
    "resampled_data = {'None': {},\n",
    "                  'over': {},\n",
    "                  'under': {},\n",
    "                  'smotenc': {},\n",
    "                  'downsample_upweight':{}}\n",
    "\n",
    "for r in resampling_techniques:\n",
    "    print('\\n----')\n",
    "    print(f'Resampling using {r}')\n",
    "\n",
    "    X_train, y_train, X_test, y_test, sample_weights, preprocessor_rsv = preprocess_and_resample_rsv(\n",
    "        df_modelling_phase1, input_test_size = input_test_size, random_seed = random_seed, resampling_technique = r)\n",
    "    \n",
    "    resampled_data[r]['X_train'] = X_train\n",
    "    resampled_data[r]['y_train'] = y_train\n",
    "    resampled_data[r]['X_test'] = X_test\n",
    "    resampled_data[r]['y_test'] = y_test\n",
    "    resampled_data[r]['sample_weights'] = sample_weights\n",
    "    resampled_data[r]['preprocessor_rsv'] = preprocessor_rsv\n",
    "    \n",
    "    IR_train = y_train.value_counts()['Negative'] / y_train.value_counts()['Positive']\n",
    "    IR_test = y_test.value_counts()['Negative'] / y_test.value_counts()['Positive']\n",
    "\n",
    "    print(f'y_TRAIN imbalance ratio: {IR_train}')\n",
    "    print(f'y_TEST imbalance ratio: {IR_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fitting of all of ML models and performance evaluaton\n",
    "- All with cost senstive learning\n",
    "- All with moving threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "Model fitted using Logistic regression and resampling: None\n",
      "Training model ... LogisticRegression(class_weight={'Negative': 1, 'Positive': 10},\n",
      "                   random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training parameters:  {'C': 0.01, 'max_iter': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best training f1-score:  0.33188139088157315\n",
      "Optimal threshold: 0.58\n",
      "Optimal f1: 0.36569987389659525\n",
      "\n",
      "\n",
      "AUC Score: 0.7912467594253123\n",
      "Precision / Positive predictive value: 0.5534351145038168\n",
      "Specificity: 0.9929860320124693\n",
      "Recall / sensitivity: 0.2730696798493409\n",
      "Negative predictive value: 0.9772271386430679\n",
      "Accuracy: 0.9707762026493144\n",
      "F-1: 0.36569987389659525\n",
      "Precision-Recall AUC: 0.34566211546801523\n",
      "\n",
      "-------------\n",
      "Model fitted using Logistic regression and resampling: over\n",
      "Training model ... LogisticRegression(class_weight={'Negative': 1, 'Positive': 10},\n",
      "                   random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training parameters:  {'C': 10, 'max_iter': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best training f1-score:  0.6313159827750442\n",
      "Optimal threshold: 0.99\n",
      "Optimal f1: 0.3490136570561457\n",
      "\n",
      "\n",
      "AUC Score: 0.7891314034901736\n",
      "Precision / Positive predictive value: 0.8984375\n",
      "Specificity: 0.9992206702236077\n",
      "Recall / sensitivity: 0.21657250470809794\n",
      "Negative predictive value: 0.975649730742215\n",
      "Accuracy: 0.9750755287009063\n",
      "F-1: 0.3490136570561457\n",
      "Precision-Recall AUC: 0.3387452372786378\n",
      "\n",
      "-------------\n",
      "Model fitted using Logistic regression and resampling: under\n",
      "Training model ... LogisticRegression(class_weight={'Negative': 1, 'Positive': 10},\n",
      "                   random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training parameters:  {'C': 1, 'max_iter': 20, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best training f1-score:  0.6312970449812979\n",
      "Optimal threshold: 0.99\n",
      "Optimal f1: 0.3538461538461539\n",
      "\n",
      "\n",
      "AUC Score: 0.788229241496381\n",
      "Precision / Positive predictive value: 0.9663865546218487\n",
      "Specificity: 0.9997602062226485\n",
      "Recall / sensitivity: 0.21657250470809794\n",
      "Negative predictive value: 0.9756625519218394\n",
      "Accuracy: 0.9755984197071811\n",
      "F-1: 0.3538461538461539\n",
      "Precision-Recall AUC: 0.336536343481789\n",
      "\n",
      "-------------\n",
      "Model fitted using Logistic regression and resampling: smotenc\n",
      "Training model ... LogisticRegression(class_weight={'Negative': 1, 'Positive': 10},\n",
      "                   random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training parameters:  {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best training f1-score:  0.6580577533397802\n",
      "Optimal threshold: 0.99\n",
      "Optimal f1: 0.35082458770614694\n",
      "\n",
      "\n",
      "AUC Score: 0.7873677225156985\n",
      "Precision / Positive predictive value: 0.8602941176470589\n",
      "Specificity: 0.9988609795575805\n",
      "Recall / sensitivity: 0.22033898305084745\n",
      "Negative predictive value: 0.9757554462403373\n",
      "Accuracy: 0.9748431326981176\n",
      "F-1: 0.35082458770614694\n",
      "Precision-Recall AUC: 0.3423451242729777\n",
      "\n",
      "-------------\n",
      "Model fitted using Logistic regression and resampling: downsample_upweight\n",
      "Training model ... LogisticRegression(class_weight={'Negative': 1, 'Positive': 10},\n",
      "                   random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training parameters:  {'C': 10, 'max_iter': 20, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best training f1-score:  0.7217919072810398\n",
      "Optimal threshold: 0.99\n",
      "Optimal f1: 0.33568406205923834\n",
      "\n",
      "\n",
      "AUC Score: 0.7858928327288249\n",
      "Precision / Positive predictive value: 0.6685393258426966\n",
      "Specificity: 0.9964630417840658\n",
      "Recall / sensitivity: 0.224105461393597\n",
      "Negative predictive value: 0.9758130797229071\n",
      "Accuracy: 0.9726353706716244\n",
      "F-1: 0.33568406205923834\n",
      "Precision-Recall AUC: 0.3299868333571074\n"
     ]
    }
   ],
   "source": [
    "model_class = LogisticRegression(random_state= random_seed, \n",
    "                                class_weight= {'Negative':1, 'Positive': 10})\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'max_iter': [20, 50],\n",
    "    'solver':['liblinear']\n",
    "}\n",
    "\n",
    "target_scorer = make_scorer(f1_score, average='binary', pos_label = 'Positive')\n",
    "n_cv_folds = 5\n",
    "\n",
    "\n",
    "for r in resampling_techniques:\n",
    "    print('\\n-------------')\n",
    "    print(f'Model fitted using Logistic regression and resampling: {r}')\n",
    "\n",
    "    X_train = resampled_data[r]['X_train']\n",
    "    y_train = resampled_data[r]['y_train']\n",
    "    X_test = resampled_data[r]['X_test']\n",
    "    y_test = resampled_data[r]['y_test']\n",
    "    sample_weights = resampled_data[r]['sample_weights'] \n",
    "\n",
    "    model1 = train_model_rsv(model = model_class, param_grid = param_grid, target_scorer = target_scorer, n_cv_folds = n_cv_folds,\n",
    "                        X_train = X_train, y_train = y_train)\n",
    "    optimal_threshold = find_optimal_moving_threshold(trained_model = model1, X_test = X_test, y_test = y_test)\n",
    "\n",
    "\n",
    "    __,__,__,__,__,__,__,__ = calculate_performance_metrics_rsv(trained_model = model1, X_test = X_test, y_test = y_test,\n",
    "                                                            threshold = optimal_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "Model fitted using Logistic regression and resampling: None\n",
      "Training model ... RandomForestClassifier(class_weight={'Negative': 1, 'Positive': 10},\n",
      "                       random_state=42)\n",
      "Best training parameters:  {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 14}\n",
      "Best training f1-score:  0.36654162066416374\n",
      "Optimal threshold: 0.46\n",
      "Optimal f1: 0.35469107551487417\n",
      "\n",
      "\n",
      "AUC Score: 0.789289516100899\n",
      "Precision / Positive predictive value: 0.4518950437317784\n",
      "Specificity: 0.9887296924644805\n",
      "Recall / sensitivity: 0.2919020715630885\n",
      "Negative predictive value: 0.9777105933961705\n",
      "Accuracy: 0.967232163606786\n",
      "F-1: 0.35469107551487417\n",
      "Precision-Recall AUC: 0.3366943872200664\n",
      "\n",
      "-------------\n",
      "Model fitted using Logistic regression and resampling: over\n",
      "Training model ... RandomForestClassifier(class_weight={'Negative': 1, 'Positive': 10},\n",
      "                       random_state=42)\n",
      "Best training parameters:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 7}\n",
      "Best training f1-score:  0.8108099431196788\n",
      "Optimal threshold: 0.99\n",
      "Optimal f1: 0.30744849445324884\n",
      "\n",
      "\n",
      "AUC Score: 0.7087510955267734\n",
      "Precision / Positive predictive value: 0.97\n",
      "Specificity: 0.9998201546669864\n",
      "Recall / sensitivity: 0.18267419962335216\n",
      "Negative predictive value: 0.9746376811594203\n",
      "Accuracy: 0.9746107366953288\n",
      "F-1: 0.30744849445324884\n",
      "Precision-Recall AUC: 0.2584638194657185\n",
      "\n",
      "-------------\n",
      "Model fitted using Logistic regression and resampling: under\n",
      "Training model ... RandomForestClassifier(class_weight={'Negative': 1, 'Positive': 10},\n",
      "                       random_state=42)\n",
      "Best training parameters:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 14}\n",
      "Best training f1-score:  0.6657421235754014\n",
      "Optimal threshold: 0.97\n",
      "Optimal f1: 0.32301480484522205\n",
      "\n",
      "\n",
      "AUC Score: 0.761943598561734\n",
      "Precision / Positive predictive value: 0.5660377358490566\n",
      "Specificity: 0.9944847431209161\n",
      "Recall / sensitivity: 0.22598870056497175\n",
      "Negative predictive value: 0.9758235294117648\n",
      "Accuracy: 0.9707762026493144\n",
      "F-1: 0.32301480484522205\n",
      "Precision-Recall AUC: 0.2920469566836317\n",
      "\n",
      "-------------\n",
      "Model fitted using Logistic regression and resampling: smotenc\n",
      "Training model ... RandomForestClassifier(class_weight={'Negative': 1, 'Positive': 10},\n",
      "                       random_state=42)\n",
      "Best training parameters:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 7}\n",
      "Best training f1-score:  0.8179492629896611\n",
      "Optimal threshold: 0.96\n",
      "Optimal f1: 0.28923076923076924\n",
      "\n",
      "\n",
      "AUC Score: 0.7408015547307281\n",
      "Precision / Positive predictive value: 0.7899159663865546\n",
      "Specificity: 0.9985012888915533\n",
      "Recall / sensitivity: 0.17702448210922786\n",
      "Negative predictive value: 0.9744339788217399\n",
      "Accuracy: 0.9731582616778991\n",
      "F-1: 0.28923076923076924\n",
      "Precision-Recall AUC: 0.2570289229054839\n",
      "\n",
      "-------------\n",
      "Model fitted using Logistic regression and resampling: downsample_upweight\n",
      "Training model ... RandomForestClassifier(class_weight={'Negative': 1, 'Positive': 10},\n",
      "                       random_state=42)\n",
      "Best training parameters:  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 14}\n",
      "Best training f1-score:  0.7446843197940595\n",
      "Optimal threshold: 0.97\n",
      "Optimal f1: 0.3154034229828851\n",
      "\n",
      "\n",
      "AUC Score: 0.7613939018094156\n",
      "Precision / Positive predictive value: 0.44947735191637633\n",
      "Specificity: 0.9905281457946167\n",
      "Recall / sensitivity: 0.24293785310734464\n",
      "Negative predictive value: 0.9762481536189069\n",
      "Accuracy: 0.9674645596095747\n",
      "F-1: 0.3154034229828851\n",
      "Precision-Recall AUC: 0.283160817338798\n"
     ]
    }
   ],
   "source": [
    "cost_sensitive = True\n",
    "if cost_sensitive:\n",
    "    weight_dict = {'Negative': 1, 'Positive': 10}\n",
    "    model_class = RandomForestClassifier(class_weight= weight_dict, random_state= random_seed)\n",
    "else:\n",
    "    model_class = RandomForestClassifier(class_weight= None, random_state= random_seed)\n",
    "    \n",
    "param_grid = {\n",
    "    'n_estimators': [7, 14],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [1, 4]\n",
    "}\n",
    "\n",
    "\n",
    "target_scorer = make_scorer(f1_score, average='binary', pos_label = 'Positive')\n",
    "n_cv_folds = 5\n",
    "\n",
    "\n",
    "for r in resampling_techniques:\n",
    "    print('\\n-------------')\n",
    "    print(f'Model fitted using Random Forest and resampling: {r}')\n",
    "\n",
    "    X_train = resampled_data[r]['X_train']\n",
    "    y_train = resampled_data[r]['y_train']\n",
    "    X_test = resampled_data[r]['X_test']\n",
    "    y_test = resampled_data[r]['y_test']\n",
    "    sample_weights = resampled_data[r]['sample_weights'] \n",
    "\n",
    "    model1 = train_model_rsv(model = model_class, param_grid = param_grid, target_scorer = target_scorer, n_cv_folds = n_cv_folds,\n",
    "                        X_train = X_train, y_train = y_train, sample_weights = sample_weights)\n",
    "    optimal_threshold = find_optimal_moving_threshold(trained_model = model1, X_test = X_test, y_test = y_test)\n",
    "\n",
    "\n",
    "    __,__,__,__,__,__,__,__ = calculate_performance_metrics_rsv(trained_model = model1, X_test = X_test, y_test = y_test,\n",
    "                                                            threshold = optimal_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "Model fitted using LightGBM and resampling: None\n",
      "Training model ... LGBMClassifier(class_weight={'Negative': 1, 'Positive': 10}, objective='binary',\n",
      "               random_state=42)\n",
      "Best training parameters:  {'learning_rate': 0.05, 'max_depth': 9, 'n_estimators': 15, 'subsample': 0.7}\n",
      "Best training f1-score:  0.37566572907957885\n",
      "Optimal threshold: 0.45\n",
      "Optimal f1: 0.35857805255023184\n",
      "\n",
      "\n",
      "AUC Score: 0.7882138874692058\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.2184557438794727\n",
      "Negative predictive value: 0.9757253158633599\n",
      "Accuracy: 0.975888914710667\n",
      "F-1: 0.35857805255023184\n",
      "Precision-Recall AUC: 0.34406210133077086\n",
      "\n",
      "-------------\n",
      "Model fitted using LightGBM and resampling: over\n",
      "Training model ... LGBMClassifier(class_weight={'Negative': 1, 'Positive': 10}, objective='binary',\n",
      "               random_state=42)\n",
      "Best training parameters:  {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 25, 'subsample': 0.7}\n",
      "Best training f1-score:  0.6652001604756863\n",
      "Optimal threshold: 0.97\n",
      "Optimal f1: 0.35348837209302325\n",
      "\n",
      "\n",
      "AUC Score: 0.7908652231397382\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.21468926553672316\n",
      "Negative predictive value: 0.9756111825944555\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.35348837209302325\n",
      "Precision-Recall AUC: 0.34134397853713566\n",
      "\n",
      "-------------\n",
      "Model fitted using LightGBM and resampling: under\n",
      "Training model ... LGBMClassifier(class_weight={'Negative': 1, 'Positive': 10}, objective='binary',\n",
      "               random_state=42)\n",
      "Best training parameters:  {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 25, 'subsample': 0.7}\n",
      "Best training f1-score:  0.648321486982616\n",
      "Optimal threshold: 0.96\n",
      "Optimal f1: 0.36229749631811486\n",
      "\n",
      "\n",
      "AUC Score: 0.792383521922559\n",
      "Precision / Positive predictive value: 0.831081081081081\n",
      "Specificity: 0.9985012888915533\n",
      "Recall / sensitivity: 0.23163841807909605\n",
      "Negative predictive value: 0.9760900140646976\n",
      "Accuracy: 0.9748431326981176\n",
      "F-1: 0.36229749631811486\n",
      "Precision-Recall AUC: 0.35060502685559247\n",
      "\n",
      "-------------\n",
      "Model fitted using LightGBM and resampling: smotenc\n",
      "Training model ... LGBMClassifier(class_weight={'Negative': 1, 'Positive': 10}, objective='binary',\n",
      "               random_state=42)\n",
      "Best training parameters:  {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 25, 'subsample': 0.7}\n",
      "Best training f1-score:  0.7284554857523396\n",
      "Optimal threshold: 0.9500000000000001\n",
      "Optimal f1: 0.35348837209302325\n",
      "\n",
      "\n",
      "AUC Score: 0.7783617952967228\n",
      "Precision / Positive predictive value: 1.0\n",
      "Specificity: 1.0\n",
      "Recall / sensitivity: 0.21468926553672316\n",
      "Negative predictive value: 0.9756111825944555\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.35348837209302325\n",
      "Precision-Recall AUC: 0.3306582795748386\n",
      "\n",
      "-------------\n",
      "Model fitted using LightGBM and resampling: downsample_upweight\n",
      "Training model ... LGBMClassifier(class_weight={'Negative': 1, 'Positive': 10}, objective='binary',\n",
      "               random_state=42)\n",
      "Best training parameters:  {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 25, 'subsample': 0.7}\n",
      "Best training f1-score:  0.7349984288054003\n",
      "Optimal threshold: 0.98\n",
      "Optimal f1: 0.36529680365296807\n",
      "\n",
      "\n",
      "AUC Score: 0.7908028474043396\n",
      "Precision / Positive predictive value: 0.9523809523809523\n",
      "Specificity: 0.9996403093339727\n",
      "Recall / sensitivity: 0.22598870056497175\n",
      "Negative predictive value: 0.9759452183073861\n",
      "Accuracy: 0.9757727167092726\n",
      "F-1: 0.36529680365296807\n",
      "Precision-Recall AUC: 0.34490568638406865\n"
     ]
    }
   ],
   "source": [
    "cost_sensitive = True\n",
    "random_seed = 42  # As before, set your own seed\n",
    "\n",
    "if cost_sensitive:\n",
    "    weight_dict = {'Negative': 1, 'Positive': 10}\n",
    "    model_class = lgb.LGBMClassifier(class_weight=weight_dict, random_state=random_seed, objective='binary')\n",
    "else:\n",
    "    model_class = lgb.LGBMClassifier(random_state=random_seed, objective='binary')\n",
    "\n",
    "# LightGBM-specific parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 15, 25],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.7, 0.9, 1]\n",
    "}\n",
    "\n",
    "target_scorer = make_scorer(f1_score, average='binary', pos_label='Positive')\n",
    "n_cv_folds = 5\n",
    "\n",
    "# Assuming resampled_data and other functions are defined elsewhere\n",
    "for r in resampling_techniques:\n",
    "    print('\\n-------------')\n",
    "    print(f'Model fitted using LightGBM and resampling: {r}')\n",
    "\n",
    "    X_train = resampled_data[r]['X_train']\n",
    "    y_train = resampled_data[r]['y_train']\n",
    "    X_test = resampled_data[r]['X_test']\n",
    "    y_test = resampled_data[r]['y_test']\n",
    "    sample_weights = resampled_data[r]['sample_weights']\n",
    "\n",
    "    model1 = train_model_rsv(model=model_class, param_grid=param_grid, target_scorer=target_scorer, n_cv_folds=n_cv_folds,\n",
    "                             X_train=X_train, y_train=y_train)\n",
    "    optimal_threshold = find_optimal_moving_threshold(trained_model=model1, X_test=X_test, y_test=y_test)\n",
    "\n",
    "    __, __, __, __, __, __, __, __ = calculate_performance_metrics_rsv(trained_model=model1, X_test=X_test, y_test=y_test,\n",
    "                                                                       threshold=optimal_threshold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
